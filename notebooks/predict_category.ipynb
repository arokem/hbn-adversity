{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c6fdaf-532a-460b-b731-5741fed0a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import afqinsight as afqi\n",
    "import afqinsight.nn.tf_models as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "\n",
    "from afqinsight import AFQDataset\n",
    "from afqinsight.plot import plot_tract_profiles\n",
    "from afqinsight.match import mahalonobis_dist_match\n",
    "from neurocombat_sklearn import CombatModel\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20817cb0-086f-4691-9cdd-a597d30d329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_participants_tsv = \"s3://fcp-indi/data/Projects/HBN/BIDS_curated/derivatives/qsiprep/participants.tsv\"\n",
    "df_participants = pd.read_csv(fn_participants_tsv, sep=\"\\t\", usecols=(\"subject_id\", \"dl_qc_score\"))\n",
    "df_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd8ad4-4abf-400e-ab98-7d1cfc6e6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_participants[\"dl_qc_score\"] == 0.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee5fc3-4bba-469c-8eca-23012c8ef907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(assessment, target_cols, matching_target, norm_high=True, qc_cutoff=0.0, median_split=False):\n",
    "    print(assessment, matching_target)\n",
    "    workdir = f\"../{assessment}\"\n",
    "    fn_nodes=op.join(workdir, \"combined_tract_profiles_merged.csv\")\n",
    "    fn_subjects=op.join(workdir, \"pheno_merged.csv\")\n",
    "\n",
    "    unsupervised_dataset = AFQDataset.from_files(\n",
    "        fn_nodes=fn_nodes,\n",
    "        dwi_metrics=[\"dki_fa\", \"dki_md\"],\n",
    "        unsupervised=True,\n",
    "        concat_subject_session=True,\n",
    "    )\n",
    "\n",
    "    dataset = AFQDataset.from_files(\n",
    "        fn_nodes=fn_nodes,\n",
    "        fn_subjects=fn_subjects,\n",
    "        dwi_metrics=[\"dki_fa\", \"dki_md\"],\n",
    "        target_cols=[\"Barratt_Total\", \"Age\", \"Sex\"] + target_cols\n",
    "    )\n",
    "    \n",
    "    subjects = [sub.split(\"HBNsite\")[0] for sub in unsupervised_dataset.subjects]\n",
    "    sites = [sub.split(\"HBNsite\")[1] for sub in unsupervised_dataset.subjects]\n",
    "\n",
    "    assert dataset.subjects == subjects\n",
    "    dataset.sessions = sites\n",
    "\n",
    "    df_y = pd.DataFrame(index=dataset.subjects, data=dataset.y, columns=dataset.target_cols)\n",
    "    df_y = pd.merge(df_y, df_participants, left_index=True, right_on=\"subject_id\", how=\"left\")\n",
    "    df_y[\"Site\"] = dataset.sessions\n",
    "    \n",
    "    # Filter based on QC cutoff\n",
    "    qc_pass_mask = df_y[\"dl_qc_score\"] > qc_cutoff\n",
    "    df_y = df_y[qc_pass_mask]\n",
    "    dataset.X = dataset.X[qc_pass_mask]\n",
    "    # dataset.subjects = [sub for idx, sub in enumerate(dataset.subjects) if qc_pass_mask[idx]]\n",
    "\n",
    "    df_y[\"site_index\"] = df_y[\"Site\"].map({\n",
    "        \"RU\": 0.0,\n",
    "        \"SI\": 1.0,\n",
    "        \"CBIC\": 2.0,\n",
    "        \"CUNY\": 3.0,\n",
    "    })\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    X_imputed = imputer.fit_transform(dataset.X)\n",
    "\n",
    "    X_site_harmonized = CombatModel().fit_transform(\n",
    "        X_imputed,\n",
    "        df_y[[\"site_index\"]],\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "    \n",
    "    df_nodes = pd.DataFrame(data=X_site_harmonized, index=df_y.index)\n",
    "\n",
    "    sns.histplot(data=df_y, x=matching_target)\n",
    "    \n",
    "    if median_split:\n",
    "        quantiles = [0.0, 0.5, 1.0]        \n",
    "    else:\n",
    "        if norm_high:\n",
    "            quantiles = [0.0, 0.33, 0.5, 1.0]\n",
    "        else:\n",
    "            quantiles = [0.0, 0.5, 0.66, 1.0]\n",
    "    \n",
    "    df_y[\"status\"] = pd.qcut(df_y[matching_target], quantiles, labels=False)\n",
    "    \n",
    "    if not median_split:\n",
    "        df_y = df_y[df_y[\"status\"] != 1]\n",
    "        df_y[\"status\"] /= 2\n",
    "\n",
    "    feature_cols = [\"Age\", \"Sex\"]\n",
    "    if assessment != \"barratt\":\n",
    "        feature_cols += [\"Barratt_Total\"]\n",
    "        \n",
    "    matched = mahalonobis_dist_match(\n",
    "        df_y, status_col=\"status\",\n",
    "        feature_cols=feature_cols\n",
    "    )\n",
    "    \n",
    "    sns.pairplot(\n",
    "        data=matched,\n",
    "        vars=[\"Barratt_Total\", \"Age\", \"Sex\"] + target_cols,\n",
    "        hue=\"status\"\n",
    "    )\n",
    "    \n",
    "    df_nodes_matched = pd.DataFrame(index=matched.index).merge(\n",
    "        df_nodes, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "    df_nodes_unmatched = df_nodes[~df_nodes.index.isin(matched.index)]\n",
    "    # unmatched = df_y.loc[df_nodes_unmatched.index]\n",
    "\n",
    "    X_matched = afqi.datasets.bundles2channels(\n",
    "        df_nodes_matched.to_numpy(),\n",
    "        n_nodes=100,\n",
    "        n_channels=48,\n",
    "        channels_last=True,\n",
    "    ).astype(np.float64)\n",
    "    \n",
    "    X_unmatched = afqi.datasets.bundles2channels(\n",
    "        df_nodes_unmatched.to_numpy(),\n",
    "        n_nodes=100,\n",
    "        n_channels=48,\n",
    "        channels_last=True,\n",
    "    ).astype(np.float64)\n",
    "\n",
    "    return {\n",
    "        \"X_matched\": X_matched,\n",
    "        \"y_matched\": matched,\n",
    "        \"X_unmatched\": X_unmatched,\n",
    "        # \"y_unmatched\": unmatched,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f72ac-2a62-46cd-bf06-03de6d615c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assessments = {\n",
    "    \"nles\": [\"NLES_P_TotalEvents\", \"NLES_P_Upset_Total\"],\n",
    "    \"apq\": [\"APQ_P_CP\", \"APQ_SR_CP\"],\n",
    "    \"cpic\": [\"CPIC_Perceived_Threat_Total\"],\n",
    "    \"wisc\": [\"WISC_FSIQ\"],\n",
    "}\n",
    "\n",
    "datasets = {\n",
    "    measure: get_dataset(\n",
    "        assessment=assessment,\n",
    "        target_cols=targets,\n",
    "        matching_target=measure,\n",
    "        norm_high=assessment==\"wisc\",\n",
    "        median_split=assessment==\"cpic\",\n",
    "    )\n",
    "    for assessment, targets in assessments.items()\n",
    "    for measure in targets\n",
    "}\n",
    "\n",
    "datasets[\"Barratt_Total\"] = get_dataset(\n",
    "    assessment=\"barratt\", target_cols=[], matching_target=\"Barratt_Total\", norm_high=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616adeb-d614-41ce-90f4-1219262be8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure, dset in datasets.items():\n",
    "    print(measure, len(dset[\"X_unmatched\"]), len(dset[\"X_matched\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b871538-1c57-4ebc-adac-ec8232ef9e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_classification_model(dataset, epochs=1000, lr=0.0001, output_activation=\"softmax\", n_classes=2):\n",
    "    model = nn.cnn_resnet(\n",
    "        input_shape=(100, 48),\n",
    "        n_classes=n_classes,\n",
    "        output_activation=output_activation,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            'accuracy', \n",
    "            tf.keras.metrics.AUC(name=\"roc_auc\"),\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # ModelCheckpoint\n",
    "    ckpt_filepath = tempfile.NamedTemporaryFile().name + '.h5'\n",
    "    ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = ckpt_filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode=\"auto\",\n",
    "    )\n",
    "    \n",
    "    # EarlyStopping\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        mode=\"min\",\n",
    "        patience=100\n",
    "    )\n",
    "\n",
    "    # ReduceLROnPlateau\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=20,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    callbacks = [early_stopping, reduce_lr, ckpt]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        dataset[\"X_matched\"],\n",
    "        pd.get_dummies(dataset[\"y_matched\"][\"status\"]).to_numpy().astype(np.float64),\n",
    "        random_state=0,\n",
    "    )\n",
    "        \n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_split=0.33, callbacks=callbacks)\n",
    "    model.load_weights(ckpt_filepath)\n",
    "    \n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(dict(y_true=y_test.flatten(),\n",
    "                          y_pred=model.predict(X_test).flatten(),\n",
    "                          split=\"test\")),\n",
    "        pd.DataFrame(dict(y_true=y_train.flatten(),\n",
    "                          y_pred=model.predict(X_train).flatten(),\n",
    "                          split=\"train\")),\n",
    "    ])\n",
    "        \n",
    "    return dict(\n",
    "        model=model,\n",
    "        y_pred=model.predict(X_test).flatten(),\n",
    "        y_test=y_test.flatten(),\n",
    "        X_test=X_test,\n",
    "        df=df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6874e4e-c9e0-4f41-8aca-2b74bba6236f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpic_results = train_classification_model(datasets[\"CPIC_Perceived_Threat_Total\"])\n",
    "apq_p_results = train_classification_model(datasets[\"APQ_P_CP\"])\n",
    "apq_sr_results = train_classification_model(datasets[\"APQ_SR_CP\"])\n",
    "nles_tot_results = train_classification_model(datasets[\"NLES_P_TotalEvents\"])\n",
    "nles_upset_results = train_classification_model(datasets[\"NLES_P_Upset_Total\"])\n",
    "barratt_results = train_classification_model(datasets[\"Barratt_Total\"])\n",
    "wisc_results = train_classification_model(datasets[\"WISC_FSIQ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813bbbc-0a9f-44cb-b9e8-b702f71db339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(covariate, results):\n",
    "    y_true = results[\"y_test\"].flatten()\n",
    "    y_pred = results[\"y_pred\"].flatten()\n",
    "    y_prob = results[\"y_prob\"].flatten()\n",
    "    y_delta = y_true - y_pred\n",
    "    \n",
    "    df = results[\"df\"].copy()\n",
    "    # sns.swarmplot(x=\"y_true\", y=\"y_prob\", data=df, hue=\"split\")\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob[:len(y_pred)])\n",
    "    \n",
    "    print(covariate)\n",
    "    print(\"=\" * len(covariate))\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"ROC AUC: {roc_auc}\")\n",
    "    print(f\"model.classes_: {results['model'].classes_}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5079f-1231-4519-904f-0b435f1c035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"CPIC_Perceived_Threat_Total\": cpic_results,\n",
    "    \"APQ_P_CP\": apq_p_results,\n",
    "    \"APQ_SR_CP\": apq_sr_results,\n",
    "    \"NLES_P_TotalEvents\": nles_tot_results,\n",
    "    \"NLES_P_Upset_Total\": nles_upset_results,\n",
    "    \"Barratt_Total\": barratt_results,\n",
    "    \"WISC_FSIQ\": wisc_results,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd8830-77e6-4df4-ad53-860133416500",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, res in results.items():\n",
    "    report(key, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537cd516-2b78-4307-9554-10047aa932de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
