{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c6fdaf-532a-460b-b731-5741fed0a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import afqinsight as afqi\n",
    "import afqinsight.nn.tf_models as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import tensorflow as tf\n",
    "\n",
    "from afqinsight import AFQDataset\n",
    "from afqinsight.plot import plot_tract_profiles\n",
    "from afqinsight.match import mahalonobis_dist_match\n",
    "from neurocombat_sklearn import CombatModel\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f556ca-6adb-4e65-a09e-5ea241f6776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_dir = op.join(\"..\", \"ses\")\n",
    "\n",
    "df_ses = pd.read_csv(op.join(ses_dir, \"pheno_merged.csv\"))\n",
    "df_ses.rename(columns={\n",
    "    \"FSQ_08\": \"family_size\",\n",
    "    \"FSQ_04\": \"income_category\",\n",
    "}, inplace=True)\n",
    "\n",
    "income_map = {\n",
    "    idx: (idx + 1) * 10000 - 5000 for idx in range(10)\n",
    "}\n",
    "income_map[10] = 125000\n",
    "income_map[11] = 175000\n",
    "income_map[12] = np.nan\n",
    "\n",
    "df_ses[\"income\"] = df_ses[\"income_category\"].map(income_map)\n",
    "df_ses[\"assistance\"] = df_ses.filter(like=\"FSQ_05\").sum(axis=\"columns\")\n",
    "df_ses.drop([col for col in df_ses.columns if \"FSQ\" in col], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242f526-5a16-478a-8cf8-0a838bebbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poverty_limit_df(year):\n",
    "    xls_rows = [8, 12] + list(range(15, 22))\n",
    "    poverty = pd.read_excel(\n",
    "        f\"https://www2.census.gov/programs-surveys/cps/tables/time-series/\"\n",
    "        f\"historical-poverty-thresholds/thresh{year[-2:]}.xls\",\n",
    "        header=1,\n",
    "    ).iloc[xls_rows, 0:2]\n",
    "    poverty.columns = [\"family_size\", \"limit\"]\n",
    "    poverty[\"family_size\"] = list(range(1, 10))\n",
    "    poverty.set_index(\"family_size\", inplace=True)\n",
    "    return poverty\n",
    "\n",
    "years = [str(yr) for yr in range(2016, 2021)]\n",
    "poverty = {\n",
    "    year: get_poverty_limit_df(year) for year in years\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee0ab53-f171-4b70-8e54-2a7f98d2ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inr(row):\n",
    "    income = row.income\n",
    "    family_size = row.family_size\n",
    "    year = str(row.Enroll_Year)\n",
    "    needs = poverty[year].loc[family_size].to_numpy()[0]\n",
    "    return income / needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b9743-612b-435d-82d5-a4d96639e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ses[\"inr\"] = df_ses.apply(get_inr, axis=\"columns\")\n",
    "df_ses.drop([\"Enroll_Year\", \"income_category\", \"family_size\", \"income\"], axis=\"columns\", inplace=True)\n",
    "df_ses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f02c7-13ad-46d4-81ac-b29a54668c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ses.to_csv(op.join(ses_dir, \"inr.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e21a50-1556-48e3-ab18-cf967adb8deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_ses, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c8e98b-f8a1-4759-8945-b3cbae7ed288",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_participants_tsv = \"s3://fcp-indi/data/Projects/HBN/BIDS_curated/derivatives/qsiprep/participants.tsv\"\n",
    "df_participants = pd.read_csv(fn_participants_tsv, sep=\"\\t\", usecols=(\"subject_id\", \"dl_qc_score\"))\n",
    "df_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee5fc3-4bba-469c-8eca-23012c8ef907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(assessment, target_cols, matching_target, norm_high=True, qc_cutoff=0.0, median_split=False):\n",
    "    print(assessment, matching_target)\n",
    "    workdir = f\"../{assessment}\"\n",
    "    fn_nodes=op.join(workdir, \"combined_tract_profiles_merged.csv\")\n",
    "    fn_subjects=op.join(workdir, \"pheno_merged.csv\")\n",
    "\n",
    "    unsupervised_dataset = AFQDataset.from_files(\n",
    "        fn_nodes=fn_nodes,\n",
    "        dwi_metrics=[\"dki_fa\", \"dki_md\"],\n",
    "        unsupervised=True,\n",
    "        concat_subject_session=True,\n",
    "    )\n",
    "\n",
    "    dataset = AFQDataset.from_files(\n",
    "        fn_nodes=fn_nodes,\n",
    "        fn_subjects=fn_subjects,\n",
    "        dwi_metrics=[\"dki_fa\", \"dki_md\"],\n",
    "        target_cols=[\"Barratt_Total\", \"Age\", \"Sex\"] + target_cols\n",
    "    )\n",
    "    \n",
    "    subjects = [sub.split(\"HBNsite\")[0] for sub in unsupervised_dataset.subjects]\n",
    "    sites = [sub.split(\"HBNsite\")[1] for sub in unsupervised_dataset.subjects]\n",
    "\n",
    "    assert dataset.subjects == subjects\n",
    "    dataset.sessions = sites\n",
    "\n",
    "    df_y = pd.DataFrame(index=dataset.subjects, data=dataset.y, columns=dataset.target_cols)\n",
    "    df_y = pd.merge(df_y, df_participants, left_index=True, right_on=\"subject_id\", how=\"left\")\n",
    "    df_y[\"Site\"] = dataset.sessions\n",
    "    \n",
    "    # Filter based on QC cutoff\n",
    "    qc_pass_mask = df_y[\"dl_qc_score\"] > qc_cutoff\n",
    "    df_y = df_y[qc_pass_mask]\n",
    "    dataset.X = dataset.X[qc_pass_mask]\n",
    "    # dataset.subjects = [sub for idx, sub in enumerate(dataset.subjects) if qc_pass_mask[idx]]\n",
    "\n",
    "    df_y[\"site_index\"] = df_y[\"Site\"].map({\n",
    "        \"RU\": 0.0,\n",
    "        \"SI\": 1.0,\n",
    "        \"CBIC\": 2.0,\n",
    "        \"CUNY\": 3.0,\n",
    "    })\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    X_imputed = imputer.fit_transform(dataset.X)\n",
    "\n",
    "    X_site_harmonized = CombatModel().fit_transform(\n",
    "        X_imputed,\n",
    "        df_y[[\"site_index\"]],\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "    \n",
    "    df_nodes = pd.DataFrame(data=X_site_harmonized, index=df_y.index)\n",
    "\n",
    "    sns.histplot(data=df_y, x=matching_target)\n",
    "    \n",
    "    if median_split:\n",
    "        quantiles = [0.0, 0.5, 1.0]        \n",
    "    else:\n",
    "        if norm_high:\n",
    "            quantiles = [0.0, 0.33, 0.5, 1.0]\n",
    "        else:\n",
    "            quantiles = [0.0, 0.5, 0.66, 1.0]\n",
    "    \n",
    "    df_y[\"status\"] = pd.qcut(df_y[matching_target], quantiles, labels=False)\n",
    "    \n",
    "    if not median_split:\n",
    "        df_y = df_y[df_y[\"status\"] != 1]\n",
    "        df_y[\"status\"] /= 2\n",
    "\n",
    "    feature_cols = [\"Age\", \"Sex\"]\n",
    "    if assessment != \"barratt\":\n",
    "        feature_cols += [\"Barratt_Total\"]\n",
    "        \n",
    "    matched = mahalonobis_dist_match(\n",
    "        df_y, status_col=\"status\",\n",
    "        feature_cols=feature_cols\n",
    "    )\n",
    "    \n",
    "    sns.pairplot(\n",
    "        data=matched,\n",
    "        vars=[\"Barratt_Total\", \"Age\", \"Sex\"] + target_cols,\n",
    "        hue=\"status\"\n",
    "    )\n",
    "    \n",
    "    df_nodes_matched = pd.DataFrame(index=matched.index).merge(\n",
    "        df_nodes, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "    df_nodes_unmatched = df_nodes[~df_nodes.index.isin(matched.index)]\n",
    "    unmatched = df_y[~df_y.index.isin(matched.index)]\n",
    "\n",
    "    X_matched = df_nodes_matched.to_numpy()    \n",
    "    X_unmatched = df_nodes_unmatched.to_numpy()\n",
    "    \n",
    "    return {\n",
    "        \"X_matched\": X_matched,\n",
    "        \"y_matched\": matched,\n",
    "        \"X_unmatched\": X_unmatched,\n",
    "        \"y_unmatched\": unmatched,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f72ac-2a62-46cd-bf06-03de6d615c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assessments = {\n",
    "    \"nles\": [\"NLES_P_TotalEvents\", \"NLES_P_Upset_Total\"],\n",
    "    \"apq\": [\"APQ_P_CP\", \"APQ_SR_CP\"],\n",
    "    \"cpic\": [\"CPIC_Perceived_Threat_Total\"],\n",
    "    \"wisc\": [\"WISC_FSIQ\"],\n",
    "}\n",
    "\n",
    "datasets = {\n",
    "    measure: get_dataset(\n",
    "        assessment=assessment,\n",
    "        target_cols=targets,\n",
    "        matching_target=measure,\n",
    "        norm_high=assessment==\"wisc\",\n",
    "        median_split=assessment==\"cpic\",\n",
    "    )\n",
    "    for assessment, targets in assessments.items()\n",
    "    for measure in targets\n",
    "}\n",
    "\n",
    "datasets[\"Barratt_Total\"] = get_dataset(\n",
    "    assessment=\"barratt\", target_cols=[], matching_target=\"Barratt_Total\", norm_high=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f6bec-ee4c-409b-a125-7862b468d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "df_unmatched = pd.concat([datasets[\"NLES_P_TotalEvents\"][\"y_unmatched\"], datasets[\"NLES_P_TotalEvents\"][\"y_matched\"]])\n",
    "df_matched = datasets[\"NLES_P_TotalEvents\"][\"y_matched\"].copy()\n",
    "\n",
    "df_matched[\"age_bin\"] = df_matched[\"Age\"].round().astype(int)\n",
    "df_unmatched[\"age_bin\"] = df_unmatched[\"Age\"].round().astype(int)\n",
    "\n",
    "df_count_matched = df_matched.groupby([\"age_bin\", \"status\"])[\"NLES_P_TotalEvents\"].count().reset_index()\n",
    "df_count_unmatched = df_unmatched.groupby([\"age_bin\", \"status\"])[\"NLES_P_TotalEvents\"].count().reset_index()\n",
    "\n",
    "columns = [\"Age\", \"status\", \"count\"]\n",
    "df_count_matched.columns = columns\n",
    "df_count_unmatched.columns = columns\n",
    "\n",
    "df_count_matched.loc[df_count_matched[\"status\"] == 0.0, \"count\"] *= -1\n",
    "df_count_unmatched.loc[df_count_unmatched[\"status\"] == 0.0, \"count\"] *= -1\n",
    "\n",
    "df_count_matched[\"NLES\"] = df_count_matched[\"status\"].map({0.0: \"Matched Low\", 1.0: \"Matched High\"})\n",
    "df_count_unmatched[\"NLES\"] = df_count_unmatched[\"status\"].map({0.0: \"Original Low\", 1.0: \"Original High\"})\n",
    "\n",
    "df_count = pd.concat([df_count_matched, df_count_unmatched])\n",
    "\n",
    "for status in [0.0, 1.0]:\n",
    "    _ = sns.barplot(\n",
    "        x=\"count\", y='Age',\n",
    "        data=df_count_unmatched[df_count_unmatched[\"status\"] == status],\n",
    "        hue_order=[\"Matched Low\", \"Matched High\"],\n",
    "        orient='horizontal', \n",
    "        dodge=False,\n",
    "        ax=ax,\n",
    "        lw=0,\n",
    "        color=\"Gray\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    \n",
    "_ = sns.barplot(\n",
    "    x=\"count\", y='Age',\n",
    "    data=df_count_matched,\n",
    "    hue='NLES',\n",
    "    hue_order=[\"Matched Low\", \"Matched High\"],\n",
    "    orient='horizontal', \n",
    "    dodge=False,\n",
    "    ax=ax,\n",
    "    lw=0,\n",
    ")\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Count\", fontsize=18)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "    \n",
    "ax.set_ylabel(\"Age\", fontsize=18)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "labels = [\"Original data\"] + labels\n",
    "handles = [Rectangle((0, 0), 1, 1, color=\"Gray\", alpha=0.7)] + handles\n",
    "\n",
    "_ = ax.legend(handles, labels, fontsize=16, title=\"NLES\", title_fontsize=18)\n",
    "\n",
    "xticklabels = [str(int(tick)).replace(\"-\", \"\") for tick in ax.get_xticks()]\n",
    "_ = ax.set_xticklabels(xticklabels)\n",
    "_ = ax.set_title(\"Original and Matched Cohorts\", fontsize=20)\n",
    "\n",
    "fig.savefig(\"matching.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5176a-02ff-4e33-b6b7-d31c4e25aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.xkcd():\n",
    "    fig0, ax0 = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    fig2, ax2 = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    \n",
    "    ax2.plot([0, 1], [0, 1], ls=\"-\", marker=\"\", color=\"black\")\n",
    "    ax2.vlines([0.2, 0.8], [0.55, 0.45], [0.2, 0.8], color=\"black\", ls=\"--\")\n",
    "    ax2.plot([0.2], [0.55], marker=\"o\", mec=\"black\", mfc=\"white\", ms=10, mew=3)\n",
    "    ax2.plot([0.5], [0.50], marker=\"o\", mec=\"black\", mfc=\"white\", ms=10, mew=3)\n",
    "    ax2.plot([0.8], [0.45], marker=\"o\", mec=\"black\", mfc=\"white\", ms=10, mew=3)\n",
    "    ax2.text(s=\"Positive BAG\", x=0.2, y=0.6, transform=ax2.transAxes, ha=\"center\", va=\"bottom\", fontsize=18)\n",
    "    ax2.text(s=\"Negative BAG\", x=0.8, y=0.4, transform=ax2.transAxes, ha=\"center\", va=\"top\", fontsize=18)\n",
    "\n",
    "    for ax in [ax0, ax2]:\n",
    "        ax.tick_params(\n",
    "            axis='both',\n",
    "            which='both',\n",
    "            bottom=False,\n",
    "            top=False,\n",
    "            left=False,\n",
    "            right=False,\n",
    "            labelbottom=False,\n",
    "            labelleft=False,\n",
    "        )\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "    ax2.set_xlabel(\"Chronological Age\", fontsize=18)\n",
    "    ax2.set_ylabel(\"Brain Age\", fontsize=18)\n",
    "    ax0.set_xlabel(\"Tract Profile\", fontsize=18)\n",
    "\n",
    "    df_bundles = pd.read_csv(\"../nles/combined_tract_profiles_merged.csv\")\n",
    "    df_plot_bundles = df_bundles[df_bundles[\"tractID\"].isin([\"CST_L\", \"CST_R\"])]\n",
    "    sns.lineplot(data=df_plot_bundles, x=\"nodeID\", y=\"dki_fa\", hue=\"tractID\", ax=ax0)\n",
    "    ax0.legend().set_visible(False)\n",
    "    \n",
    "    ax0.set_title(\"Potential Group Difference\", fontsize=18)\n",
    "    ax2.set_title(\"Brain Age Gap (BAG) Analysis\", fontsize=18)\n",
    "    \n",
    "    fig0.savefig(\"tract_profile_diff.pdf\", bbox_inches=\"tight\")\n",
    "    fig2.savefig(\"bag_analysis_cartoon.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616adeb-d614-41ce-90f4-1219262be8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure, dset in datasets.items():\n",
    "    print(measure, len(dset[\"X_unmatched\"]), len(dset[\"X_matched\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55eb51-116f-46b7-975e-75dc269010eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"Barratt_Total\"][\"y_matched\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b871538-1c57-4ebc-adac-ec8232ef9e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_classification_model(dataset, standard_scale=True):\n",
    "    model = afqi.pipeline.make_base_afq_pipeline(\n",
    "        imputer_kwargs={\"strategy\": \"median\"},\n",
    "        feature_transformer=PCA,\n",
    "        scaler=\"standard\",\n",
    "        estimator=LogisticRegressionCV,\n",
    "        estimator_kwargs={\n",
    "            \"verbose\": 0,\n",
    "            \"Cs\": 50,\n",
    "            \"penalty\": \"l1\",\n",
    "            \"cv\": 3,\n",
    "            \"n_jobs\": 8,\n",
    "            \"solver\": \"saga\",\n",
    "            \"max_iter\": 5000,\n",
    "        },\n",
    "        verbose=0,\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        dataset[\"X_matched\"],\n",
    "        dataset[\"y_matched\"][\"status\"].to_numpy().astype(np.float64),\n",
    "        random_state=0,\n",
    "        stratify=dataset[\"y_matched\"][\"status\"].to_numpy().astype(np.float64),\n",
    "    )\n",
    "        \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    df = pd.concat([\n",
    "        pd.DataFrame(dict(y_true=y_test.flatten(),\n",
    "                          y_pred=model.predict(X_test).flatten(),\n",
    "                          y_prob=model.predict_proba(X_test)[:, 1],\n",
    "                          split=\"test\")),\n",
    "        pd.DataFrame(dict(y_true=y_train.flatten(),\n",
    "                          y_pred=model.predict(X_train).flatten(),\n",
    "                          y_prob=model.predict_proba(X_train)[:, 1],\n",
    "                          split=\"train\")),\n",
    "    ])\n",
    "        \n",
    "    return dict(\n",
    "        model=model,\n",
    "        y_pred=model.predict(X_test).flatten(),\n",
    "        y_prob=model.predict_proba(X_test)[:, 1],\n",
    "        y_test=y_test.flatten(),\n",
    "        X_test=X_test,\n",
    "        df=df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6874e4e-c9e0-4f41-8aca-2b74bba6236f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpic_results = train_classification_model(datasets[\"CPIC_Perceived_Threat_Total\"])\n",
    "apq_p_results = train_classification_model(datasets[\"APQ_P_CP\"])\n",
    "apq_sr_results = train_classification_model(datasets[\"APQ_SR_CP\"])\n",
    "nles_tot_results = train_classification_model(datasets[\"NLES_P_TotalEvents\"])\n",
    "nles_upset_results = train_classification_model(datasets[\"NLES_P_Upset_Total\"])\n",
    "barratt_results = train_classification_model(datasets[\"Barratt_Total\"])\n",
    "wisc_results = train_classification_model(datasets[\"WISC_FSIQ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813bbbc-0a9f-44cb-b9e8-b702f71db339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(covariate, results):\n",
    "    y_true = results[\"y_test\"].flatten()\n",
    "    y_pred = results[\"y_pred\"].flatten()\n",
    "    y_prob = results[\"y_prob\"].flatten()\n",
    "    y_delta = y_true - y_pred\n",
    "    \n",
    "    df = results[\"df\"].copy()\n",
    "    # sns.swarmplot(x=\"y_true\", y=\"y_prob\", data=df, hue=\"split\")\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob[:len(y_pred)])\n",
    "    \n",
    "    print(covariate)\n",
    "    print(\"=\" * len(covariate))\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"ROC AUC: {roc_auc}\")\n",
    "    print(f\"model.classes_: {results['model'].classes_}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5079f-1231-4519-904f-0b435f1c035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"CPIC_Perceived_Threat_Total\": cpic_results,\n",
    "    \"APQ_P_CP\": apq_p_results,\n",
    "    \"APQ_SR_CP\": apq_sr_results,\n",
    "    \"NLES_P_TotalEvents\": nles_tot_results,\n",
    "    \"NLES_P_Upset_Total\": nles_upset_results,\n",
    "    \"Barratt_Total\": barratt_results,\n",
    "    # \"WISC_FSIQ\": wisc_results,\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    \"CPIC_Perceived_Threat_Total\": \"CPIC-threat\",\n",
    "    \"APQ_P_CP\": \"APQ-CP (parent)\",\n",
    "    \"APQ_SR_CP\": \"APQ-CP (child)\",\n",
    "    \"NLES_P_TotalEvents\": \"NLES-events\",\n",
    "    \"NLES_P_Upset_Total\": \"NLES-upset\",\n",
    "    \"Barratt_Total\": \"BSMSS\",\n",
    "    # \"WISC_FSIQ\": wisc_results,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd8830-77e6-4df4-ad53-860133416500",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, res in results.items():\n",
    "    report(key, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537cd516-2b78-4307-9554-10047aa932de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(9, 5))\n",
    "\n",
    "ax.plot([0, 1], [0, 1], ls=\"--\", lw=3, color=\"black\", label=\"Chance\")\n",
    "\n",
    "for key, res in results.items():\n",
    "    pos_label = res[\"model\"].classes_[0] if key in [\"Barratt_Total\", \"WISC_FSIQ\"] else res[\"model\"].classes_[1]\n",
    "    _ = RocCurveDisplay.from_estimator(res[\"model\"], res[\"X_test\"], res[\"y_test\"], ax=ax, pos_label=pos_label, name=labels[key])\n",
    "\n",
    "_ = ax.set_xlabel(\"False Positive Rate\", fontsize=18)\n",
    "_ = ax.set_ylabel(\"True Positive Rate\", fontsize=18)\n",
    "_ = ax.set_title(\"ROC Curve\", fontsize=20)\n",
    "_ = ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "_ = ax.legend(fontsize=14, loc=\"lower right\", bbox_to_anchor=(1.14, 0.0))\n",
    "_ = fig.savefig(\"roc_curve_pcr_lasso.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b643697a-8cd8-4207-a5a0-259599ec0eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ee588-29c7-496c-818a-761c13622958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_matched = datasets[\"NLES_P_TotalEvents\"][\"y_matched\"].copy()\n",
    "nodes_matched = datasets[\"NLES_P_TotalEvents\"][\"X_matched\"].copy()\n",
    "\n",
    "high_mask = df_y_matched[\"status\"].astype(bool).to_numpy()\n",
    "low_mask = ~high_mask\n",
    "\n",
    "nodes_high = nodes_matched[high_mask]\n",
    "nodes_low = nodes_matched[low_mask]\n",
    "\n",
    "node_tests = []\n",
    "for col_num in range(nodes_matched.shape[1]):\n",
    "    levene = stats.levene(nodes_high[:, col_num], nodes_low[:, col_num])\n",
    "    shapiro_low = stats.shapiro(nodes_low[:, col_num])\n",
    "    shapiro_high = stats.shapiro(nodes_high[:, col_num])\n",
    "    ttest = stats.ttest_ind(nodes_low[:, col_num], nodes_high[:, col_num])\n",
    "    wilcoxon = stats.wilcoxon(nodes_low[:, col_num], nodes_high[:, col_num])\n",
    "    \n",
    "    node_tests.append({\n",
    "        \"node\": col_num,\n",
    "        \"levene_statistic\": levene.statistic,\n",
    "        \"levene_pvalue\": levene.pvalue,\n",
    "        \"low_shapiro_statistic\": shapiro_low.statistic,\n",
    "        \"low_shapiro_pvalue\": shapiro_low.pvalue,\n",
    "        \"high_shapiro_statistic\": shapiro_high.statistic,\n",
    "        \"high_shapiro_pvalue\": shapiro_high.pvalue,\n",
    "        \"ttest_statistic\": ttest.statistic,\n",
    "        \"ttest_pvalue\": ttest.pvalue,\n",
    "        \"wilcoxon_statistic\": wilcoxon.statistic,\n",
    "        \"wilcoxon_pvalue\": wilcoxon.pvalue,        \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a23a4-a69a-4d30-a3a3-c2866ed96f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests = pd.DataFrame(node_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebc925-a59f-4956-86ef-0e4a5983c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tests[df_tests[\"ttest_pvalue\"] < 0.05 / df_tests.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a18c4-787f-452f-a63b-352bcd15d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tests[df_tests[\"wilcoxon_pvalue\"] < 0.05 / df_tests.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc8cf4-1caa-42ef-941e-9af44aaad357",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tests[df_tests[\"ttest_pvalue\"] < 0.05]) / len(df_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f84dd9a-d6cb-4307-8d66-d2cde5a55875",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tests[df_tests[\"wilcoxon_pvalue\"] < 0.05]) / len(df_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5802242-0eeb-4445-b232-9bc8644484a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d449d8-9964-4584-90d9-253e3bf8920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdr = multipletests(df_tests[\"ttest_pvalue\"], method=\"fdr_bh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d2c032-0f22-403e-a764-14bbe5f7cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "maov_dicts = []\n",
    "for bundle_idx in range(nodes_matched.shape[1]//100):\n",
    "    col_low = bundle_idx * 100\n",
    "    col_high = col_low + 100\n",
    "    col_names = [f\"node{idx}\" for idx in range(100)]\n",
    "    df_bundle_high = pd.DataFrame(columns=col_names, data=nodes_high[:, col_low:col_high])\n",
    "    df_bundle_low = pd.DataFrame(columns=col_names, data=nodes_low[:, col_low:col_high])\n",
    "    df_bundle_high[\"ela\"] = 1\n",
    "    df_bundle_low[\"ela\"] = 0\n",
    "    df_bundle = pd.concat([df_bundle_low, df_bundle_high])\n",
    "    df_bundle[\"ela\"] = df_bundle[\"ela\"].astype(int)\n",
    "    \n",
    "    formula = \"node0 \"\n",
    "    for idx in range(1, 100):\n",
    "        formula += f\" + node{idx} \"\n",
    "    \n",
    "    formula += \"~ ela\"\n",
    "    \n",
    "    maov = MANOVA.from_formula(formula, data=df_bundle)\n",
    "    maov_test_dict = maov.mv_test().results[\"ela\"][\"stat\"][\"Pr > F\"].to_dict()\n",
    "    maov_test_dict[\"bundle_idx\"] = bundle_idx\n",
    "    maov_dicts.append(maov_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af5fa1-8300-460b-81a1-facadf73dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manova = pd.DataFrame(maov_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7bdc97-ea42-4b1b-9d21-12e0dcb6b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_type in df_manova.columns[:4]:\n",
    "    print(len(df_manova[df_manova[test_type] < 0.05]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f504121-f992-4893-bce5-a1baa7d00099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
