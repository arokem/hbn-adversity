{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c6fdaf-532a-460b-b731-5741fed0a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import afqinsight as afqi\n",
    "import afqinsight.nn.tf_models as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import tensorflow as tf\n",
    "import tempfile\n",
    "\n",
    "from afqinsight import AFQDataset\n",
    "from afqinsight.plot import plot_tract_profiles\n",
    "from afqinsight.match import mahalonobis_dist_match\n",
    "from neurocombat_sklearn import CombatModel\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015fc89d-a21d-4352-982e-985da007024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_participants_tsv = \"s3://fcp-indi/data/Projects/HBN/BIDS_curated/derivatives/qsiprep/participants.tsv\"\n",
    "df_participants = pd.read_csv(fn_participants_tsv, sep=\"\\t\", usecols=(\"subject_id\", \"dl_qc_score\"))\n",
    "df_participants[\"dl_qc_score\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f70afe1-f9f0-4aca-8e46-104a5e1374af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee5fc3-4bba-469c-8eca-23012c8ef907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(assessment, target_cols, matching_target, norm_high=True, qc_cutoff=0.0, median_split=False):\n",
    "    print(assessment, matching_target)\n",
    "    workdir = f\"../{assessment}\"\n",
    "    fn_nodes=op.join(workdir, \"combined_tract_profiles_merged.csv\")\n",
    "    fn_subjects=op.join(workdir, \"pheno_merged.csv\")\n",
    "\n",
    "    unsupervised_dataset = AFQDataset.from_files(\n",
    "        fn_nodes=fn_nodes,\n",
    "        dwi_metrics=[\"dki_fa\", \"dki_md\"],\n",
    "        unsupervised=True,\n",
    "        concat_subject_session=True,\n",
    "    )\n",
    "\n",
    "    dataset = AFQDataset.from_files(\n",
    "        fn_nodes=fn_nodes,\n",
    "        fn_subjects=fn_subjects,\n",
    "        dwi_metrics=[\"dki_fa\", \"dki_md\"],\n",
    "        target_cols=[\"Barratt_Total\", \"Age\", \"Sex\"] + target_cols\n",
    "    )\n",
    "    \n",
    "    subjects = [sub.split(\"HBNsite\")[0] for sub in unsupervised_dataset.subjects]\n",
    "    sites = [sub.split(\"HBNsite\")[1] for sub in unsupervised_dataset.subjects]\n",
    "\n",
    "    assert dataset.subjects == subjects\n",
    "    dataset.sessions = sites\n",
    "\n",
    "    df_y = pd.DataFrame(index=dataset.subjects, data=dataset.y, columns=dataset.target_cols)\n",
    "    df_y = pd.merge(df_y, df_participants, left_index=True, right_on=\"subject_id\", how=\"left\")\n",
    "    df_y[\"Site\"] = dataset.sessions\n",
    "    \n",
    "    # Filter based on QC cutoff\n",
    "    qc_pass_mask = df_y[\"dl_qc_score\"] > qc_cutoff\n",
    "    df_y = df_y[qc_pass_mask]\n",
    "    dataset.X = dataset.X[qc_pass_mask]\n",
    "    # dataset.subjects = [sub for idx, sub in enumerate(dataset.subjects) if qc_pass_mask[idx]]\n",
    "\n",
    "    df_y[\"site_index\"] = df_y[\"Site\"].map({\n",
    "        \"RU\": 0.0,\n",
    "        \"SI\": 1.0,\n",
    "        \"CBIC\": 2.0,\n",
    "        \"CUNY\": 3.0,\n",
    "    })\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    X_imputed = imputer.fit_transform(dataset.X)\n",
    "\n",
    "    X_site_harmonized = CombatModel().fit_transform(\n",
    "        X_imputed,\n",
    "        df_y[[\"site_index\"]],\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "    \n",
    "    df_nodes = pd.DataFrame(data=X_site_harmonized, index=df_y.index)\n",
    "\n",
    "    sns.histplot(data=df_y, x=matching_target)\n",
    "    \n",
    "    df_y_orig = df_y.copy()\n",
    "\n",
    "    if median_split:\n",
    "        quantiles = [0.0, 0.5, 1.0]        \n",
    "    else:\n",
    "        if norm_high:\n",
    "            quantiles = [0.0, 0.33, 0.5, 1.0]\n",
    "        else:\n",
    "            quantiles = [0.0, 0.5, 0.66, 1.0]\n",
    "    \n",
    "    df_y[\"status\"] = pd.qcut(df_y[matching_target], quantiles, labels=False)\n",
    "    \n",
    "    if not median_split:\n",
    "        df_y = df_y[df_y[\"status\"] != 1]\n",
    "        df_y[\"status\"] /= 2\n",
    "\n",
    "    feature_cols = [\"Age\", \"Sex\"]\n",
    "    if assessment != \"barratt\":\n",
    "        feature_cols += [\"Barratt_Total\"]\n",
    "        \n",
    "    matched = mahalonobis_dist_match(\n",
    "        df_y, status_col=\"status\",\n",
    "        feature_cols=feature_cols\n",
    "    )\n",
    "    \n",
    "    sns.pairplot(\n",
    "        data=matched,\n",
    "        vars=[\"Barratt_Total\", \"Age\", \"Sex\"] + target_cols,\n",
    "        hue=\"status\"\n",
    "    )\n",
    "    \n",
    "    df_nodes_matched = pd.DataFrame(index=matched.index).merge(\n",
    "        df_nodes, how=\"left\", left_index=True, right_index=True\n",
    "    )\n",
    "    df_nodes_unmatched = df_nodes[~df_y_orig[\"subject_id\"].isin(matched[\"subject_id\"])]\n",
    "    unmatched = df_y_orig[~df_y_orig[\"subject_id\"].isin(matched[\"subject_id\"])]\n",
    "\n",
    "    X_matched = afqi.datasets.bundles2channels(\n",
    "        df_nodes_matched.to_numpy(),\n",
    "        n_nodes=100,\n",
    "        n_channels=48,\n",
    "        channels_last=True,\n",
    "    ).astype(np.float64)\n",
    "    \n",
    "    X_unmatched = afqi.datasets.bundles2channels(\n",
    "        df_nodes_unmatched.to_numpy(),\n",
    "        n_nodes=100,\n",
    "        n_channels=48,\n",
    "        channels_last=True,\n",
    "    ).astype(np.float64)\n",
    "\n",
    "    return {\n",
    "        \"X_matched\": X_matched,\n",
    "        \"y_matched\": matched,\n",
    "        \"X_unmatched\": X_unmatched,\n",
    "        \"y_unmatched\": unmatched,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f72ac-2a62-46cd-bf06-03de6d615c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assessments = {\n",
    "    \"nles\": [\"NLES_P_TotalEvents\", \"NLES_P_Upset_Total\"],\n",
    "    \"apq\": [\"APQ_P_CP\", \"APQ_SR_CP\"],\n",
    "    \"cpic\": [\"CPIC_Perceived_Threat_Total\"],\n",
    "    \"wisc\": [\"WISC_FSIQ\"],\n",
    "}\n",
    "\n",
    "datasets = {\n",
    "    measure: get_dataset(\n",
    "        assessment=assessment,\n",
    "        target_cols=targets,\n",
    "        matching_target=measure,\n",
    "        norm_high=assessment==\"wisc\",\n",
    "        median_split=assessment==\"cpic\",\n",
    "    )\n",
    "    for assessment, targets in assessments.items()\n",
    "    for measure in targets\n",
    "}\n",
    "\n",
    "datasets[\"Barratt_Total\"] = get_dataset(\n",
    "    assessment=\"barratt\", target_cols=[], matching_target=\"Barratt_Total\", norm_high=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616adeb-d614-41ce-90f4-1219262be8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure, dset in datasets.items():\n",
    "    print(measure, len(dset[\"X_unmatched\"]), len(dset[\"X_matched\"]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cde10152-9d3d-4992-9bf5-cda3b6cf2ed3",
   "metadata": {},
   "source": [
    "Dataset sizes from simple median splits:\n",
    "NLES_P_TotalEvents 784 778\n",
    "NLES_P_Upset_Total 944 618\n",
    "WISC_FSIQ 999 346\n",
    "Barratt_Total 123 1556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53e1ca-a68a-4074-8cb7-440e7e052549",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"NLES_P_TotalEvents\"][\"y_matched\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe6f13-21bf-4f10-809c-439cfc126bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrmse(y_true, y_pred):\n",
    "    y_range = np.ptp(y_true)\n",
    "    return mean_squared_error(y_true, y_pred, squared=False) / y_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55eb51-116f-46b7-975e-75dc269010eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"Barratt_Total\"][\"y_matched\"][\"dl_qc_score\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b871538-1c57-4ebc-adac-ec8232ef9e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(dataset, epochs=1000, lr=0.01, output_activation=\"linear\", n_classes=1, normative_status=1, use_unmatched_for_training=True):\n",
    "    model = nn.cnn_resnet(\n",
    "        input_shape=(100, 48),\n",
    "        n_classes=n_classes,\n",
    "        output_activation=output_activation,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\n",
    "            'mean_squared_error', \n",
    "            tf.keras.metrics.RootMeanSquaredError(name='rmse'), \n",
    "            'mean_absolute_error'\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # ModelCheckpoint\n",
    "    ckpt_filepath = tempfile.NamedTemporaryFile().name + '.h5'\n",
    "    ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = ckpt_filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode=\"auto\",\n",
    "    )\n",
    "    \n",
    "    # EarlyStopping\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        mode=\"min\",\n",
    "        patience=100\n",
    "    )\n",
    "\n",
    "    # ReduceLROnPlateau\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=20,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    callbacks = [early_stopping, reduce_lr, ckpt]\n",
    "    \n",
    "    if use_unmatched_for_training:\n",
    "        X_train = dataset[\"X_unmatched\"]\n",
    "        X_test = dataset[\"X_matched\"]\n",
    "        y_train = dataset[\"y_unmatched\"][\"Age\"].to_numpy().astype(np.float64)\n",
    "        y_test = dataset[\"y_matched\"][\"Age\"].to_numpy().astype(np.float64)\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=epochs, validation_split=0.2, callbacks=callbacks)\n",
    "        model.load_weights(ckpt_filepath)\n",
    "        \n",
    "        df = dataset[\"y_matched\"].copy()\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_delta_test = y_pred.flatten() - y_test.flatten()\n",
    "        df[\"bag\"] = y_delta_test\n",
    "        df[\"y_pred\"] = y_pred.flatten()\n",
    "        df[\"split\"] = \"test\"\n",
    "        \n",
    "        df_train = dataset[\"y_unmatched\"].copy()\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_delta_train = y_pred_train.flatten() - y_train.flatten()\n",
    "        df_train[\"bag\"] = y_delta_train\n",
    "        df_train[\"y_pred\"] = y_pred_train.flatten()\n",
    "        df_train[\"split\"] = \"train\"\n",
    "        \n",
    "        df = pd.concat([df, df_train])\n",
    "    else:\n",
    "        train_norm_mask = (dataset[\"y_matched\"][\"status\"] == normative_status).to_numpy()\n",
    "        test_mask = np.logical_not(train_norm_mask)\n",
    "\n",
    "        train_idx, norm_idx = train_test_split(np.where(train_norm_mask)[0], test_size=0.3)\n",
    "        train_mask = np.zeros_like(test_mask).astype(bool)\n",
    "        train_mask[train_idx] = True\n",
    "\n",
    "        norm_mask = np.zeros_like(test_mask).astype(bool)\n",
    "        norm_mask[norm_idx] = True\n",
    "    \n",
    "        y_train = dataset[\"y_matched\"][\"Age\"][train_mask].to_numpy().astype(np.float64)\n",
    "        y_test = dataset[\"y_matched\"][\"Age\"][test_mask].to_numpy().astype(np.float64)\n",
    "        y_norm = dataset[\"y_matched\"][\"Age\"][norm_mask].to_numpy().astype(np.float64)\n",
    "        X_train = dataset[\"X_matched\"][train_mask]\n",
    "        X_test = dataset[\"X_matched\"][test_mask]\n",
    "        X_norm = dataset[\"X_matched\"][norm_mask]\n",
    "            \n",
    "        model.fit(X_train, y_train, epochs=epochs, validation_split=0.2, callbacks=callbacks)\n",
    "        model.load_weights(ckpt_filepath)\n",
    "    \n",
    "        df = dataset[\"y_matched\"].copy()\n",
    "        df[\"bag\"] = 0\n",
    "        df[\"y_pred\"] = 0\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_delta_test = y_pred.flatten() - y_test.flatten()\n",
    "        df.loc[test_mask, \"bag\"] = y_delta_test\n",
    "        df.loc[test_mask, \"y_pred\"] = y_pred.flatten()\n",
    "\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_delta_train = y_pred_train.flatten() - y_train.flatten()\n",
    "        df.loc[train_mask, \"bag\"] = y_delta_train\n",
    "        df.loc[train_mask, \"y_pred\"] = y_pred_train.flatten()\n",
    "\n",
    "        y_pred_norm = model.predict(X_norm)\n",
    "        y_delta_norm = y_pred_norm.flatten() - y_norm.flatten()\n",
    "        df.loc[norm_mask, \"bag\"] = y_delta_norm\n",
    "        df.loc[norm_mask, \"y_pred\"] = y_pred_norm.flatten()\n",
    "\n",
    "        df.loc[train_mask, \"split\"] = \"train\"\n",
    "        df.loc[test_mask, \"split\"] = \"test\"\n",
    "        df.loc[norm_mask, \"split\"] = \"norm\"\n",
    "    \n",
    "    return dict(\n",
    "        model=model,\n",
    "        y_pred=y_pred,\n",
    "        y_test=y_test,\n",
    "        y_delta=y_delta_test,\n",
    "        df=df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6874e4e-c9e0-4f41-8aca-2b74bba6236f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpic_results = train_model(datasets[\"CPIC_Perceived_Threat_Total\"], normative_status=0)\n",
    "apq_p_results = train_model(datasets[\"APQ_P_CP\"], normative_status=0)\n",
    "apq_sr_results = train_model(datasets[\"APQ_SR_CP\"], normative_status=0)\n",
    "nles_tot_results = train_model(datasets[\"NLES_P_TotalEvents\"], normative_status=0)\n",
    "nles_upset_results = train_model(datasets[\"NLES_P_Upset_Total\"], normative_status=0)\n",
    "barratt_results = train_model(datasets[\"Barratt_Total\"], normative_status=1)\n",
    "wisc_results = train_model(datasets[\"WISC_FSIQ\"], normative_status=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63674a-7866-4270-97c3-d8a21e7f4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813bbbc-0a9f-44cb-b9e8-b702f71db339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(covariate, results, label, use_unmatched_as_norm=True, lmplot=True):\n",
    "    y_true = results[\"y_test\"].flatten()\n",
    "    y_pred = results[\"y_pred\"].flatten()\n",
    "    y_delta = y_true - y_pred\n",
    "\n",
    "    df = results[\"df\"].copy()\n",
    "    \n",
    "    if not lmplot:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    lm = True\n",
    "    \n",
    "    if use_unmatched_as_norm:\n",
    "        df[\"Class\"] = df[\"status\"].map({0.0: \"Low\", 1.0: \"High\"})\n",
    "\n",
    "        if lmplot:\n",
    "            lm = sns.lmplot(x=\"Age\",\n",
    "                            y=\"y_pred\",\n",
    "                            data=df[df[\"split\"] != \"train\"],\n",
    "                            hue=\"Class\",\n",
    "                            legend=False,\n",
    "                            scatter_kws={\"s\": 60, \"alpha\": 0.7})\n",
    "            ax = lm.axes[0, 0]\n",
    "            _ = sns.scatterplot(\n",
    "                x=\"Age\",\n",
    "                y=\"y_pred\",\n",
    "                data=df[df[\"split\"] == \"train\"],\n",
    "                ax=ax,\n",
    "                color=\"gray\",\n",
    "                alpha=0.5,\n",
    "                zorder=-100\n",
    "            )\n",
    "            xmin, xmax = ax.get_xlim()\n",
    "            ymin, ymax = ax.get_ylim()\n",
    "            global_min = min(xmin, ymin)\n",
    "            global_max = max(xmax, ymax)\n",
    "            _ = ax.plot([global_min, global_max], [global_min, global_max], ls=\"--\", lw=2, zorder=-300, color=\"black\", label=\"BAG=0\")\n",
    "            _ = ax.set_xlim(global_min, global_max)\n",
    "            _ = ax.set_ylim(global_min, global_max)\n",
    "            _ = ax.set_ylabel(\"Brain Age\", fontsize=18)\n",
    "            _ = ax.set_xlabel(\"Chronological Age\", fontsize=18)\n",
    "            _ = ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "            _ = ax.legend(fontsize=14, title=label, title_fontsize=14)\n",
    "        else:\n",
    "            sns.scatterplot(x=\"Age\", y=\"y_pred\", data=df[df[\"split\"] == \"train\"], ax=axes[0], color=\"gray\", alpha=0.7)\n",
    "            sns.scatterplot(x=\"Age\", y=\"y_pred\", data=df[df[\"split\"] != \"train\"], hue=\"Class\", ax=axes[0])\n",
    "        \n",
    "        if not lmplot:\n",
    "            ymin, ymax = axes[0].get_ylim()\n",
    "            xmin, xmax = axes[0].get_xlim()\n",
    "            axes[0].plot([0, 100], [0, 100], color=\"black\", ls=\"--\", lw=3)\n",
    "            axes[0].set_xlim(xmin, xmax)\n",
    "            axes[0].set_ylim(ymin, ymax)\n",
    "\n",
    "        df[\"bag\"] = df[\"Age\"] - df[\"y_pred\"]\n",
    "        \n",
    "        if not lmplot:\n",
    "            sns.violinplot(data=df, x=\"Class\", y=\"bag\")\n",
    "    else:\n",
    "        df = df[df[\"split\"] != \"train\"]\n",
    "\n",
    "        sns.scatterplot(x=\"Age\", y=\"y_pred\", data=df, hue=\"split\", ax=axes[0])\n",
    "        ymin, ymax = axes[0].get_ylim()\n",
    "        xmin, xmax = axes[0].get_xlim()\n",
    "        axes[0].plot([0, 100], [0, 100], color=\"black\", ls=\"--\", lw=3)\n",
    "        axes[0].set_xlim(xmin, xmax)\n",
    "        axes[0].set_ylim(ymin, ymax)\n",
    "\n",
    "        df[\"bag\"] = df[\"Age\"] - df[\"y_pred\"]\n",
    "        sns.violinplot(data=df, x=\"split\", y=\"bag\", ax=axes[1])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    df[\"Scaled_Age\"] = scaler.fit_transform(df[\"Age\"].to_numpy()[:, np.newaxis]).flatten()\n",
    "    df[covariate] = scaler.fit_transform(df[covariate].to_numpy()[:, np.newaxis]).flatten()\n",
    "    \n",
    "    formula = f\"bag ~ Scaled_Age + Sex + {covariate}\"\n",
    "    mod = sm.GLM.from_formula(formula, df).fit()\n",
    "    \n",
    "    print(covariate)\n",
    "    print(\"=\" * len(covariate))\n",
    "    print(f\"Subject: RMSE={mean_squared_error(y_true, y_pred, squared=False)}\")\n",
    "    print(f\"Subject: nRMSE={nrmse(y_true, y_pred)}\")\n",
    "    print(f\"Subject: mean(bag)={np.mean(y_delta)}\")\n",
    "    print()\n",
    "    print(mod.summary())\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5079f-1231-4519-904f-0b435f1c035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"CPIC_Perceived_Threat_Total\": cpic_results,\n",
    "    \"APQ_P_CP\": apq_p_results,\n",
    "    \"APQ_SR_CP\": apq_sr_results,\n",
    "    \"NLES_P_TotalEvents\": nles_tot_results,\n",
    "    \"NLES_P_Upset_Total\": nles_upset_results,\n",
    "    \"Barratt_Total\": barratt_results,\n",
    "    \"WISC_FSIQ\": wisc_results,\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    \"CPIC_Perceived_Threat_Total\": \"CPIC-threat\",\n",
    "    \"APQ_P_CP\": \"APQ-CP (parent)\",\n",
    "    \"APQ_SR_CP\": \"APQ-CP (child)\",\n",
    "    \"NLES_P_TotalEvents\": \"NLES-events\",\n",
    "    \"NLES_P_Upset_Total\": \"NLES-upset\",\n",
    "    \"Barratt_Total\": \"BSMSS\",\n",
    "    \"WISC_FSIQ\": \"FSIQ\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fce277-8d20-4bc6-8266-1ff9ce026511",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, res in results.items():\n",
    "    score = r2_score(res[\"y_test\"], res[\"y_pred\"])\n",
    "    print(key, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd8830-77e6-4df4-ad53-860133416500",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, res in results.items():\n",
    "    res[\"lm\"] = report(key, res, label=labels[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393dddbe-6957-4353-b9b9-565c66686364",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, res in results.items():\n",
    "    res[\"lm\"].fig.savefig(f\"bag-analysis-{labels[key]}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c93dff4-304b-4c13-9916-cdfc6f370f28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
